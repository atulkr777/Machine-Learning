{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Bias - Assignment 01\n",
    "### Student name - Atul Kumar Singh (20200619)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "surv = pd.read_csv('survival.csv')\n",
    "surv['Survived'] = 'GE5'\n",
    "surv.loc[surv['Class']==2,'Survived']='L5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv['Survived'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc=surv['Survived'].value_counts() \n",
    "y = surv.pop('Survived').values\n",
    "surv.pop('Class')\n",
    "X = surv.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all = {}\n",
    "\n",
    "model_all['kNN']= KNeighborsClassifier(n_neighbors=3)\n",
    "model_all['dtree'] = DecisionTreeClassifier(max_depth=2,criterion='entropy')\n",
    "model_all['logistic'] = LogisticRegression(random_state=42,max_iter=10000)\n",
    "model_all['gradient']= GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold out testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.5, random_state=42)\n",
    "acc_bal = {}\n",
    "predictedMinority={}\n",
    "\n",
    "print(\"shape of training and test samples:\")\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(\"Total count of Minority class L5 in test set: {}\".format(len(y_test)-Counter(y_test)['GE5']))\n",
    "for m in model_all:\n",
    "    y_pred = model_all[m].fit(X_train, y_train).predict(X_test)\n",
    "    acc_bal[m] = accuracy_score(y_test, y_pred)\n",
    "    predictedMinority[m] = len(y_pred)-(Counter(y_pred)['GE5'])\n",
    "    print(\"Result of {:22}, predicted minority {:d}, accuracy {:.2f}\".format(type(model_all[m]).__name__,predictedMinority[m],acc_bal[m]))\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Add the prior figures to the data for plotting\n",
    "objects = ['Prior'] + list(predictedMinority.keys())\n",
    "positive = [len(y_test)-Counter(y_test)['GE5']] + list(predictedMinority.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "print(len(y_test)-Counter(y_test)['GE5'])\n",
    "\n",
    "plt.bar(y_pos, positive, align='center', color=['red', 'blue', 'blue','blue','blue'],alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Minority Count')\n",
    "plt.title('ML Algorithm Bias')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the hold out testing we observed that all algorithms are biased towards majority class.\n",
    "- KNN has bias of about 60 %\n",
    "- Decision tree has bias of about 36%\n",
    "- Logistic Regression and decision tree has very high bias.\n",
    "- Gradient Boosting has bias of 19 % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation to check bias in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "scoring = {'tp' : make_scorer(tp), 'tn' : make_scorer(tn),\n",
    "       'fp' : make_scorer(fp), 'fn' : make_scorer(fn)}\n",
    "\n",
    "\n",
    "folds = 10\n",
    "v = 0 \n",
    "\n",
    "bias_cv = {}\n",
    "\n",
    "for m in model_all:\n",
    "    cv_results = cross_validate(model_all[m], X, y, cv= folds,scoring=scoring, return_train_score=False, \n",
    "                                verbose = v, n_jobs = -1)\n",
    "    n_total = cv_results['test_tp'].sum() + cv_results['test_fp'].sum()\n",
    "    accuracy = (cv_results['test_tp'].sum() + cv_results['test_tn'].sum())/len(y)\n",
    "    bias_cv[m] = n_total\n",
    "\n",
    "    print(\"{} x CV {:22} N: {:d} Pred N: {:d} Acc: {:.2f}\".format(folds, type(model_all[m]).__name__, \n",
    "                                                              vc[1],n_total,accuracy))\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "objects = ['Prior'] + list(bias_cv.keys())\n",
    "positive = [vc[1]] + list(bias_cv.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, positive, align='center', color=['red', 'blue', 'blue','blue','blue','blue'],alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Minority Count')\n",
    "plt.title('ML Algorithm Bias - Cross Validation')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* on cross validating the models using k=10, it is observed that almost all models except gradient boosting where bias is very low.\n",
    "* In CV , the entire dataset in different folds is considered to verify the efficacy of the model. Taking a higher value of K reduces the probability of bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do up sampling using KMeans SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# splitting data into training and testing pairs\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.5, random_state=42)\n",
    "\n",
    "print(\"Before upsampling training set {}\".format(Counter(y_train)))\n",
    "\n",
    "smk=KMeansSMOTE(sampling_strategy=0.7,random_state=42)\n",
    "X_trainUP,y_trainUP=smk.fit_resample(X_train,y_train)\n",
    "print(\"After sampling training set {}\".format(Counter(y_trainUP)))\n",
    "\n",
    "acc_bal = {}\n",
    "predictedMinority={}\n",
    "\n",
    "print(\"Total count of Minority class L5 in test set: {}\".format(len(y_test)-Counter(y_test)['GE5']))\n",
    "for m in model_all:\n",
    "    y_pred = model_all[m].fit(X_trainUP, y_trainUP).predict(X_test)\n",
    "    acc_bal[m] = accuracy_score(y_test, y_pred)\n",
    "    predictedMinority[m] = len(y_pred)-(Counter(y_pred)['GE5'])\n",
    "    print(\"Result of {:22}, predicted minority {:d}, accuracy {:.2f}\".format(type(model_all[m]).__name__,predictedMinority[m],acc_bal[m]))\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Add the prior figures to the data for plotting\n",
    "objects = ['Prior'] + list(predictedMinority.keys())\n",
    "positive = [len(y_test)-Counter(y_test)['GE5']] + list(predictedMinority.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "print(len(y_test)-Counter(y_test)['GE5'])\n",
    "\n",
    "plt.bar(y_pos, positive, align='center', color=['red', 'blue', 'blue','blue','blue'],alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Minority Count')\n",
    "plt.title('Upsampling result')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on upsampling\n",
    "* To reduce the bias, I have used KMeansSMOTE() method with sampling strategy =70 % Here, minority class is about 70 percent of the majority count. The KMeansSMOTE avoids generation of noise during upsampling and effectively overcomes imbalances between and within classes.\n",
    "* The solution works pretty well in all the models.\n",
    "* Bias is reduced in all the models. Accuracy of KNN,Logistic Regression has minimal impact and accuracy of Decision Tree increases by ~3%. Accuracy of Gradient boosting remains unchanged.\n",
    "* KNN has the best balance between bias and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel = pd.read_csv('HotelRev.csv')\n",
    "hotel.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel['reviewHelpfulness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=hotel.pop('reviewHelpfulness').values\n",
    "X=hotel.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Dataset STATS\")\n",
    "print(\"Minority class:\",len(y) - y.sum())\n",
    "print(\"Majority class:\",y.sum())\n",
    "print(\"Minority class: {:.2f}%\".format((len(y)-y.sum())/len(y)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=.5)\n",
    "predictedMinority = {}\n",
    "acc_bal = {}\n",
    "\n",
    "print(\"Minority class in test set : %d\" % (len(y_test) - y_test.sum()))\n",
    "\n",
    "for m in model_all:\n",
    "    y_pred = model_all[m].fit(X_train, y_train).predict(X_test)\n",
    "    pred_count = (len(y_pred) - y_pred.sum())\n",
    "    predictedMinority[m] = pred_count\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    acc_bal[m] = acc\n",
    "  \n",
    "\n",
    "    print(\"{:22} Pred. Unhelpful: {:d} Accuracy: {:.2f}\".\n",
    "          format(type(model_all[m]).__name__, pred_count,acc))\n",
    "    \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "# Add the prior figures to the data for plotting\n",
    "objects = ['Prior'] + list(predictedMinority.keys())\n",
    "positive = [len(y_test) - y_test.sum()] + list(predictedMinority.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, positive, align='center', color=['red', 'blue', 'blue','blue','blue'],alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Minority Count')\n",
    "plt.title('ML Algorithm Bias')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# splitting data into training and testing pairs\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.5, random_state=42)\n",
    "\n",
    "print(\"Before upsampling training set {}\".format(Counter(y_train)))\n",
    "\n",
    "#implementing oversampling with undersampling to remove tomek links \n",
    "#smk=SMOTETomek(sampling_strategy=0.7,random_state=1)\n",
    "smk=KMeansSMOTE(sampling_strategy=0.7,random_state=42)\n",
    "X_trainUP,y_trainUP=smk.fit_resample(X_train,y_train)\n",
    "print(\"After sampling training set {}\".format(Counter(y_trainUP)))\n",
    "\n",
    "acc_bal = {}\n",
    "predictedMinority={}\n",
    "\n",
    "print(\"Total count of Minority class in test set: {}\".format(len(y_test) - y_test.sum()))\n",
    "for m in model_all:\n",
    "    y_pred = model_all[m].fit(X_trainUP, y_trainUP).predict(X_test)\n",
    "    acc_bal[m] = accuracy_score(y_test, y_pred)\n",
    "    predictedMinority[m] = len(y_pred)- y_pred.sum()\n",
    "    print(\"Result of {:22}, predicted minority {:d}, accuracy {:.2f}\".format(type(model_all[m]).__name__,predictedMinority[m],acc_bal[m]))\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Add the prior figures to the data for plotting\n",
    "objects = ['Prior'] + list(predictedMinority.keys())\n",
    "positive = [len(y_test) - y_test.sum()] + list(predictedMinority.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, positive, align='center', color=['red', 'blue', 'blue','blue','blue'],alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Minority Count')\n",
    "plt.title('Up-sampling result')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the output of 2nd dataset\n",
    "* Applying KMeans SMOTE here also gives positive results.\n",
    "* Bias is reduced in all models.\n",
    "* Also, accuracy of Decision Tree, Logistic Regression, Gradient Boosting increases by a good percentage.\n",
    "* Accuracy impact on KNN in minimal.\n",
    "* Gradient boosting has the best balance between accuracy and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
